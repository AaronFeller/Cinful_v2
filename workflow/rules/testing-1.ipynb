{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "hits_df = pd.read_csv('../../resources/enterobacterales/test_blastp_blastn/results/final/hmm_hits_with_pident.csv')\n",
    "ss_df = pd.read_csv('../../resources/enterobacterales/test_blastp_blastn/results/hmmsearch/ss_domains.csv')\n",
    "gp_df = pd.read_csv('../../resources/enterobacterales/test_blastp_blastn/results/hmmsearch/ss_gram_positive_domains.csv')\n",
    "microcin_domain_hmm_df = pd.read_csv('../../resources/enterobacterales/test_blastp_blastn/results/hmmsearch/extracted_hits_domain.csv')\n",
    "\n",
    "#filter hits_df where column 'reg' is greater than 1\n",
    "ss_df = ss_df[ss_df['evalue'] < 1]\n",
    "gp_df = gp_df[gp_df['evalue'] < 1]\n",
    "microcin_domain_hmm_df = microcin_domain_hmm_df[microcin_domain_hmm_df['evalue'] < 1]\n",
    "\n",
    "#rename evalue column to evalue_signalsequence in ss_df\n",
    "ss_df = ss_df.rename(columns={'evalue': 'evalue_signal_sequence'})\n",
    "gp_df = gp_df.rename(columns={'evalue': 'evalue_gram_positive'})\n",
    "microcin_domain_hmm_df = microcin_domain_hmm_df.rename(columns={'evalue': 'evalue_microcin_domain'})\n",
    "\n",
    "#rename column 'hit_id' to 'pephash' in ss_df and gp_df\n",
    "ss_df = ss_df.rename(columns={'hit_id': 'pephash'})\n",
    "gp_df = gp_df.rename(columns={'hit_id': 'pephash'})\n",
    "microcin_domain_hmm_df = microcin_domain_hmm_df.rename(columns={'hit_id': 'contig'})\n",
    "\n",
    "#merge left hits_df and right hmm_dfs on pephash and target name\n",
    "merged_df = pd.merge(hits_df, ss_df, how='left', on='pephash')\n",
    "merged_df = pd.merge(merged_df, gp_df, how='left', on='pephash')\n",
    "merged_df = pd.merge(merged_df, microcin_domain_hmm_df, how='left', on='contig')\n",
    "\n",
    "#rename columns hit_start_x to hit_start_signalsequence and hit_start_y to hit_start_gram_positive\n",
    "merged_df = merged_df.rename(columns={'hit_start_x': 'hit_start_signal_sequence', 'hit_start_y': 'hit_start_gram_positive', 'hit_start': 'hit_start_microcin_domain'})\n",
    "\n",
    "#rename columns query_start_x to query_start_signalsequence and query_start_y to query_start_gram_positive\n",
    "merged_df = merged_df.rename(columns={'query_start_x': 'query_start_signal_sequence', 'query_start_y': 'query_start_gram_positive', 'query_start': 'query_start_microcin_domain'})\n",
    "\n",
    "#write csv merged_df\n",
    "merged_df.to_csv('../../resources/enterobacterales/test_blastp_blastn/results/final/hmm_hits_with_domain_hits.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "#load df from csv of file hmm_hits_with_ss_hit.csv\n",
    "df = pd.read_csv('../../resources/enterobacterales/test_blastp_blastn/results/final/hmm_hits_with_domain_hits.csv')\n",
    "\n",
    "#fill empty cells with nan\n",
    "df = df.fillna(np.nan)\n",
    "\n",
    "# Remove all rows that have dont have 'hit_start' and have an 'evalue' < 1\n",
    "sub_df = df[(df['evalue'] < 1) | (df['hit_start_signal_sequence'].notna()) | (df['hit_start_gram_positive'].notna())]\n",
    "\n",
    "# Shorten seq if signal sequence hmm matched\n",
    "for index, row in sub_df.iterrows():\n",
    "    if row.hit_start_signal_sequence > 0:\n",
    "        position = int(row.hit_start_signal_sequence)+int(row.query_start_signal_sequence)\n",
    "        while all(elem not in ['M'] for elem in row.seq[position]):\n",
    "            position -= 1\n",
    "        sub_df.at[index, 'seq'] = row.seq[position:]\n",
    "        \n",
    "# Shorten seq if gram positive hmm matched\n",
    "for index, row in sub_df.iterrows():\n",
    "    if row.hit_start_gram_positive > 0:\n",
    "        position = int(row.hit_start_gram_positive)+int(row.query_start_gram_positive)\n",
    "        while all(elem not in ['M'] for elem in row.seq[position]):\n",
    "            position -= 1\n",
    "        sub_df.at[index, 'seq'] = row.seq[position:]\n",
    "\n",
    "# remove all rows with query_start_microcin_domain > 140\n",
    "sub_df = sub_df[(sub_df['query_start_microcin_domain'] <= 5) | sub_df['query_start_microcin_domain'].isna()]\n",
    "\n",
    "# Shorten seq with original full sequence HMM if neither gram+ or ss matched\n",
    "for index, row in sub_df.iterrows():\n",
    "    if row.hit_start_microcin_domain > 0:\n",
    "        if not pd.notna(row.hit_start_signal_sequence) and not pd.notna(row.hit_start_gram_positive):\n",
    "            position = int(row.hit_start_microcin_domain)+int(row.query_start_microcin_domain)\n",
    "            while all(elem not in ['M'] for elem in row.seq[position]):\n",
    "                position -= 1\n",
    "            # Replace seq in sub_df with row.seq[position:]\n",
    "            sub_df.at[index, 'seq'] = row.seq[position:]\n",
    "\n",
    "# remove rows with length over 140\n",
    "sub_df = sub_df[sub_df['seq'].str.len() <= 140]\n",
    "\n",
    "# Write CSV\n",
    "sub_df.to_csv('../../resources/enterobacterales/test_blastp_blastn/results/final/best_hits_short.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "VSGAGAP\n",
      "True\n",
      "ISGAGEF\n",
      "True\n",
      "VYGSVDN\n",
      "True\n",
      "VSGAGNV\n",
      "True\n",
      "IAAAGDF\n",
      "True\n",
      "VPGAGDV\n",
      "True\n",
      "ISGGDGG\n",
      "True\n",
      "VSGAGNY\n",
      "True\n",
      "MKLIGGC\n",
      "True\n",
      "ISGAGDR\n",
      "True\n",
      "ISGGRGG\n",
      "True\n",
      "VSGGDGG\n",
      "True\n",
      "DLISGGN\n",
      "True\n",
      "VSGGDSG\n",
      "True\n",
      "VSGGDSG\n",
      "True\n",
      "VSGGNAN\n",
      "True\n",
      "IYGSDGN\n",
      "True\n",
      "VYGGDGG\n",
      "False\n",
      "DSKAMED\n",
      "False\n",
      "QYTVNPN\n",
      "True\n",
      "TSGSDGN\n",
      "True\n",
      "VYGGDGG\n",
      "True\n",
      "IAGGRGN\n",
      "True\n",
      "ISGGNAD\n",
      "True\n",
      "ISGGNAD\n",
      "False\n",
      "RRLSALE\n",
      "True\n",
      "IGGGGES\n",
      "True\n",
      "VSGGDSG\n",
      "True\n",
      "VSGAGFF\n",
      "True\n",
      "VDGGGDG\n",
      "True\n",
      "ISGGWTA\n",
      "True\n",
      "VSGGDDF\n",
      "True\n",
      "NVSGGNA\n",
      "True\n",
      "VDGGGDG\n",
      "True\n",
      "VNGGGVV\n",
      "False\n",
      "LHNEREL\n",
      "True\n",
      "VSGAYGD\n",
      "True\n",
      "ASAAGTP\n",
      "True\n",
      "VSGAGVI\n",
      "True\n",
      "VAGGDGA\n",
      "True\n",
      "VSGAGFF\n",
      "True\n",
      "VSGGEFV\n",
      "False\n",
      "KSGHIFS\n",
      "True\n",
      "VSGAWTS\n",
      "False\n",
      "VVVTQDK\n",
      "True\n",
      "VNGGCIE\n",
      "True\n",
      "IAGAGNF\n",
      "True\n",
      "VSGAGGL\n",
      "True\n",
      "VTGASGA\n",
      "False\n",
      "EIAFISG\n",
      "True\n",
      "VDGGFGL\n",
      "False\n",
      "PYYWCNS\n",
      "True\n",
      "VQGGILP\n",
      "True\n",
      "VNGAGII\n",
      "False\n",
      "SEEIKTV\n",
      "True\n",
      "VSGGSFF\n",
      "False\n",
      "VSGCGLI\n",
      "True\n",
      "VTGGVAP\n",
      "True\n",
      "VNGAGFV\n",
      "True\n",
      "VSGGASS\n",
      "True\n",
      "VSGAGAL\n",
      "True\n",
      "DSIAGGR\n",
      "False\n",
      "TRKRALA\n",
      "True\n",
      "VSGGDYY\n",
      "True\n",
      "VSGAGLW\n",
      "False\n",
      "TRKRALA\n",
      "True\n",
      "VSGGDLN\n",
      "True\n",
      "VSGGDLN\n",
      "False\n",
      "KSEIDMI\n",
      "False\n",
      "VVVSKDK\n",
      "True\n",
      "ISGGREA\n",
      "True\n",
      "VSGAGKI\n",
      "True\n",
      "VSGAGLF\n",
      "True\n",
      "VNGGWAK\n",
      "False\n",
      "MKANALS\n",
      "False\n",
      "MKANALS\n",
      "False\n",
      "MKANALS\n",
      "True\n",
      "VSGAGLT\n",
      "True\n",
      "VSGAGLT\n",
      "True\n",
      "ISGGRGN\n",
      "True\n",
      "VSGAGFI\n",
      "True\n",
      "VFGGSKN\n",
      "True\n",
      "VNGAGKI\n",
      "True\n",
      "VSGAGWG\n",
      "False\n",
      "VFLDASP\n",
      "False\n",
      "SKIDKRA\n",
      "True\n",
      "RIGGAGD\n",
      "False\n",
      "KLLTHSV\n",
      "False\n",
      "FWIILFL\n",
      "True\n",
      "VSGAGLP\n",
      "True\n",
      "VSGSGVS\n",
      "True\n",
      "VSGGSLT\n",
      "True\n",
      "VSGAGWG\n",
      "True\n",
      "VSGGNVG\n",
      "True\n",
      "VSGSGSL\n",
      "True\n",
      "VSGGLNI\n",
      "True\n",
      "VSGAGIA\n",
      "True\n",
      "VSGAGIA\n",
      "False\n",
      "LKEMKAV\n",
      "True\n",
      "VSGSGSE\n",
      "True\n",
      "VSGGMSN\n",
      "True\n",
      "VNGATIG\n",
      "True\n",
      "VSGSGFI\n",
      "False\n",
      "MDEVDAV\n",
      "True\n",
      "VSGAGII\n",
      "True\n",
      "VAGGGLI\n",
      "True\n",
      "TSVSGAN\n",
      "True\n",
      "DLVSGAG\n",
      "False\n",
      "AKEMKAV\n",
      "False\n",
      "EIAQVSG\n",
      "True\n",
      "VAGGGLL\n",
      "True\n",
      "VSGAGRD\n",
      "True\n",
      "VSGADIG\n",
      "True\n",
      "VYGGNGG\n",
      "True\n",
      "KSVSGGG\n",
      "True\n",
      "VSGAGAS\n",
      "True\n",
      "VSGASPL\n",
      "True\n",
      "VSGGVNF\n",
      "True\n",
      "VSGACEG\n",
      "True\n",
      "ASGGREA\n",
      "True\n",
      "VSGAGSV\n",
      "True\n",
      "VAGGFTI\n"
     ]
    }
   ],
   "source": [
    "# Check that a 'G' occurs in the 12-18th position of the sequence\n",
    "#for index, row in sub_df.iterrows():\n",
    "#    print(row.seq[12:18])\n",
    "for index, row in sub_df.iterrows():\n",
    "    substring_list = [\"GG\", \"GA\", \"GT\", \"GS\", \"GD\"]\n",
    "    contains_substring = any(substring in row.seq[12:18] for substring in substring_list)\n",
    "    print(contains_substring)\n",
    "    print(row.seq[11:18])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1_PLS_43e35dac32e4e33535626414ebb39c62b8f533b825da21d2e543ef9db21d35c5\n",
      "1.7e-06\n",
      "0\n",
      "0\n",
      "v1_PLS_c7cf9039519ff486dba0f10aa4eff2f7daada6a2496366a29d391562fa6fa5da\n",
      "2.4e-06\n",
      "0\n",
      "20\n",
      "v1_PLS_dfaced24dfac66bf693b7011abd5471d8a280d6b793218895ed5498a82b57f4f\n",
      "6.2e-06\n",
      "0\n",
      "0\n",
      "v1_PLS_287df586b104fbf4f67cc43a9167a638a30b135b6befb420e4dcbc96e2b6186b\n",
      "1.1e-05\n",
      "0\n",
      "4\n",
      "v1_PLS_19a21776df0c06234ea03db35840d41fa816520e7319067065d0f82122c4d99e\n",
      "8.4e-06\n",
      "1\n",
      "7\n",
      "v1_PLS_3ccb58e107e7cdddfe931c43545c97f7dd3d7a7f77732b99859f5bbccd0430c6\n",
      "1.1e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_b0651204ee63eb822d671edee6d5704293984b9d6736f80ed35690dafcba7fe9\n",
      "1.7e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_5b6239dd42f797a40e6fcc9ca8571caa7a882d8d0aab5a95522844cece9a3e7a\n",
      "1.5e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_5352c6d709f1a1f31a68f907b9750eed689cec581d26362fe565265ecd9ed519\n",
      "1e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_6d588212416814332f2793aa6a8ec0ebfa560742c883ad5bc5b05e5b225136bf\n",
      "1e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_fb3bf6c320b4281b7f45b31e06b363862ab4ca77a544b4df29cd246146d64ce9\n",
      "1.3e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_cf121f399716d92d36e49c7a7eb89e77b7cdbeeb4a8d7973fed48c60067921e9\n",
      "3.2e-05\n",
      "2\n",
      "10\n",
      "v1_PLS_ac14b26d5537b83d4ca07cc8803cd2ae5e6fac47bf557b3137236f9cf290b403\n",
      "2.2e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_1068f51f80b750ecd87dc1f318679dc41a2c677783aa5227920144065828dd6b\n",
      "4.9e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_c0ea39f0675a4184ef76ec3547d4c5ad5a110550ba3d9160ceda6971eb142d12\n",
      "0.0001\n",
      "2\n",
      "2\n",
      "v1_PLS_deefa5778283fd95056bd209bb5b5c624ef7b6750a53427902ca8e22af85181a\n",
      "5e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_ec5c967fd1189ea1b353cb19a121618b07d2c0757a842693fcfb002b1139c0d4\n",
      "5.1e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_9527062f7f05b9d9dd4f2983145b37633fd2dc5dd14e09567947036b91baf79a\n",
      "7.4e-05\n",
      "0\n",
      "2\n",
      "v1_PLS_a681e492b26478482d673c2471a81cde21dd35285c03077c3243ced9cb95a586\n",
      "8e-05\n",
      "0\n",
      "26\n",
      "v1_PLS_6361baf780b3715482ed50f520b56b7e12ddba6ff2c9e88565f8c0b0c19556e6\n",
      "6.9e-05\n",
      "0\n",
      "6\n",
      "v1_PLS_2d51f1f3467ba030c63b280bd4f9fcca843d4c1610adfd857d2a48663d67bf56\n",
      "0.00014\n",
      "0\n",
      "0\n",
      "v1_PLS_7c29d55b8a51a99d73ea4139ba497d250f4df97a9b1d7181dbc4828d2933e9ae\n",
      "0.00012\n",
      "0\n",
      "0\n",
      "v1_PLS_e886a4cf5eb66f049cc1d51d11edeebb1f5219afe41115a7cd320e0232005638\n",
      "7.2e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_fa2dd7ad01a725cab7ba3819405f21a220c08b5eba6bb4baac177961de30477c\n",
      "0.00025\n",
      "0\n",
      "0\n",
      "v1_PLS_0d97a498dee9f122eb0e71cb26858da4ffa18e3461abbaf103b6601451f63b09\n",
      "8.3e-05\n",
      "0\n",
      "0\n",
      "v1_PLS_8c485fdc636e4a9ba12866b6867cb516cec81ae288094d021f19e97e93b2e9a0\n",
      "0.00019\n",
      "0\n",
      "4\n",
      "v1_PLS_b265b69206c70b29a2e9a7268074fae391104c3e573e174fc05025ab654c42b9\n",
      "0.00039\n",
      "0\n",
      "33\n",
      "v1_PLS_e1af1942697f0148de2e72c50c18cc0fa3b43d938c11b52902fd2d1408814743\n",
      "0.00055\n",
      "0\n",
      "0\n",
      "v1_PLS_463efaf61a2a99d5dc94d8e3b7f74db7d9662a444e4ec16e27378b3f6c906d98\n",
      "0.00043\n",
      "0\n",
      "11\n",
      "v1_PLS_d0449fa77a385a29c9a7e346c48beed99051c9d04a9f0315d1196c9a4f16b06c\n",
      "0.00024\n",
      "0\n",
      "0\n",
      "v1_PLS_7a06302484bfd0997cc5c40755dcee7c8883f0efa9daa1e8a53068752912d124\n",
      "0.0004\n",
      "0\n",
      "11\n",
      "v1_PLS_723a4c59f5c921e0bbfa5a72a02cf1333b5b483d3e1063d397bbbf98c0ea29b7\n",
      "0.0002\n",
      "0\n",
      "0\n",
      "v1_PLS_8db52a6b896c47399548b451c678ef837391a366fb3c14496a62fca8981b6f68\n",
      "0.00068\n",
      "0\n",
      "0\n",
      "v1_PLS_ff65ae26907880f656df21bf97cce1c587b118674c4681a441876f321741bfe7\n",
      "0.00041\n",
      "2\n",
      "14\n",
      "v1_PLS_00ca43d539777b9c5e7e6a371b23b0e25133303e322597afaff78a8239dbaadd\n",
      "0.00024\n",
      "0\n",
      "0\n",
      "v1_PLS_dba0774ce5a4548ec925bf4028d6d657025936896c35e9c416f610e10c4d9470\n",
      "0.00025\n",
      "0\n",
      "0\n",
      "v1_PLS_8f4e72e250be3c6e11f9da936879862dea1c270fa3cb07e66ec56e4747a80769\n",
      "0.00037\n",
      "0\n",
      "5\n",
      "v1_PLS_042f2f87ae45c4662e900202858bae48d66cb2cc1152a35dc6d648e7d73ef7bc\n",
      "0.00026\n",
      "1\n",
      "2\n",
      "v1_PLS_b039bd154c30f73a54f4946f357dd6c98de31f72e3771453fe412f9343676224\n",
      "0.00053\n",
      "3\n",
      "5\n",
      "v1_PLS_b06a580495143a4f63bbd8121f06905d2d06e477546d264cf23704ddf670e243\n",
      "0.00089\n",
      "0\n",
      "12\n",
      "v1_PLS_f3db49619e9e0e4c3c6a7badc4e49f6982b4db2ce31ce351f04bf33573f6f357\n",
      "0.00055\n",
      "1\n",
      "7\n",
      "v1_PLS_ff666a24a22ba8731f013e05bd6df2ac5a46c71894c4fa538ca9f88aab3a7c4e\n",
      "0.0012\n",
      "0\n",
      "0\n",
      "v1_PLS_9062aad7a3a37212fcf5d095a17de63ba5d14190bb44934dd96f36c44f53bce7\n",
      "0.0013\n",
      "0\n",
      "0\n",
      "v1_PLS_813b03a01f0658cf5a973a980cef45a4d633fe710d13e5133feb9c5ea1b4c18c\n",
      "0.00082\n",
      "0\n",
      "0\n",
      "v1_PLS_eb5a755f4869a0d5bc7e3a73e8453d1ba8ed674a4d002182bdd2f0d6f57b5891\n",
      "0.0011\n",
      "0\n",
      "0\n",
      "v1_PLS_84a4a18798fff583ff768abf8484368f0ce9e8fa225b1b75feda7adb11cdfdf9\n",
      "0.0014\n",
      "0\n",
      "0\n",
      "v1_PLS_4cdf30dd8130bb7bdce3b4ab88327b45bfbcf8b921e268cc51e577e5a5731aab\n",
      "0.0014\n",
      "0\n",
      "0\n",
      "v1_PLS_aa568dfb2d195dfbb78258c41ad6b95e1f1036d088a4121e4401d313aa67e87d\n",
      "0.0012\n",
      "1\n",
      "7\n",
      "v1_PLS_a8798da1a45d486bb4df963b4ec6087419f483b1abbddb1d1ba6b7ca2e1a5f6e\n",
      "0.00065\n",
      "0\n",
      "2\n",
      "v1_PLS_c6e4fb07569347a161f855f1d632e9d85b58f92b768e8affea9706cfa8366c12\n",
      "0.00072\n",
      "0\n",
      "0\n",
      "v1_PLS_42cc2e1b1b7b23393f5256d6fe9f9cd407715a814d158820eb2a3f33f53e2b10\n",
      "0.0016\n",
      "0\n",
      "0\n",
      "v1_PLS_075d55e471e23d3b9c1978d36b40cef4ec5b810ab4cf4ffbbff8ee40f89d7d70\n",
      "0.0011\n",
      "0\n",
      "0\n",
      "v1_PLS_075d55e471e23d3b9c1978d36b40cef4ec5b810ab4cf4ffbbff8ee40f89d7d70\n",
      "130.0\n",
      "10\n",
      "67\n",
      "v1_PLS_31cd5db4c8221d4fee33b31300d9559ee48caa6e196ad8c25a6b4d4e6a774745\n",
      "0.0051\n",
      "0\n",
      "0\n",
      "v1_PLS_31cd5db4c8221d4fee33b31300d9559ee48caa6e196ad8c25a6b4d4e6a774745\n",
      "130.0\n",
      "8\n",
      "63\n",
      "v1_PLS_653fae320dc76557fcdd190c23f0329b8d0d58d37e9fbb4e187b197991928ce0\n",
      "0.0019\n",
      "0\n",
      "0\n",
      "v1_PLS_b6b9e25b90defcb99b95dd762f76defb9ff75d0a7ec8f4c363a4079b7ea99f91\n",
      "0.0024\n",
      "0\n",
      "0\n",
      "v1_PLS_ef15badf261554c60afb44f6cfdc62854ed233c00653fba232434797bf10dede\n",
      "0.0027\n",
      "0\n",
      "2\n",
      "v1_PLS_50742d0aa6c9d72d90c02986118f3039c3a374c9490a4ef48f914bf194684d7e\n",
      "0.0025\n",
      "0\n",
      "0\n",
      "v1_PLS_3e3a9081d1790ee0ecabf29f87c253b82b267a09b55ebf6e392dca8fb8975b6c\n",
      "0.0015\n",
      "0\n",
      "0\n",
      "v1_PLS_9ee5781fac8c90fa85d41355a95f2142d458b6dc8ee46d7123917b1af612ce5f\n",
      "0.0016\n",
      "0\n",
      "0\n",
      "v1_PLS_3994c16c99d79a5c5ee93c727eb31d0935cd2ddda23cec6f1cc5e2748026e7ce\n",
      "0.003\n",
      "0\n",
      "0\n",
      "v1_PLS_37114e9e41269593caf20984a60f5eeddc9fab7c9b6f52e3ba3f8da4f1f4aca6\n",
      "0.005\n",
      "0\n",
      "0\n",
      "v1_PLS_fedd8733911b3d5275ff93d16d376e8c0a2b4a0cfe6595b32d25833b7ac5e0ff\n",
      "0.0084\n",
      "0\n",
      "0\n",
      "v1_PLS_d72966d83d92d0baa57e516ac3b57abec9c1b2196a4da012b0fbe041f5c3a7b9\n",
      "0.0026\n",
      "0\n",
      "0\n",
      "v1_PLS_15094462586498302152cbcf3cc8af617863e678eb0767425e9abe291b83959c\n",
      "0.0076\n",
      "0\n",
      "0\n",
      "v1_PLS_f9210ee009240faf3eab49192fd4557c440f91e2c232cf98b525d6f9312b4480\n",
      "0.0056\n",
      "0\n",
      "0\n",
      "v1_PLS_bd20cd4ab155697d363e3028a1d34057f064433a4ed50fe658d6351d1b576634\n",
      "0.0076\n",
      "0\n",
      "0\n",
      "v1_PLS_6f7d1f6708ef3c877313bdfc0a5451a640cafd6fee5bb47b1f7252b611342fe1\n",
      "0.0082\n",
      "0\n",
      "7\n",
      "v1_PLS_93d87d67ede55b0f7b2aaa9cd818f3d8e9c518e404f7347936e99153c3e4858d\n",
      "0.008\n",
      "0\n",
      "0\n",
      "v1_PLS_c0659a733d53ba405a9f11b0513524d90ee5f11f0fe2b2a236a57a3fbcf65e19\n",
      "0.0097\n",
      "1\n",
      "2\n",
      "v1_PLS_c2ea95b1a0d0cfb4eb587b53358c445b1fa7177ee1a2795b5c0eb9f920112718\n",
      "0.018\n",
      "0\n",
      "0\n",
      "v1_PLS_3f7997e743cd7888d5133692421f042ad5ea17b649f152e77a86372c8d4cad11\n",
      "0.015\n",
      "0\n",
      "0\n",
      "v1_PLS_00b108ea1413e12c0c7984af73de481aace80ffdae173cb51aef44785783496a\n",
      "0.021\n",
      "0\n",
      "0\n",
      "v1_PLS_b4d3f4b758170ad802977bb1bfd0f45de4ff9bc0254d91a6e5c5901a23fad736\n",
      "0.029\n",
      "0\n",
      "0\n",
      "v1_PLS_0522b4740b6e7f22df9f69a20c705ac24c4749259c9d6abcfc870e6bb0903cfb\n",
      "0.043\n",
      "0\n",
      "0\n",
      "v1_PLS_0522b4740b6e7f22df9f69a20c705ac24c4749259c9d6abcfc870e6bb0903cfb\n",
      "63.0\n",
      "10\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "from Bio import SearchIO\n",
    "\n",
    "hit_attribs = ['id', 'bitscore', 'evalue', 'bias']\n",
    "hsp_attribs = ['env_start', 'env_end']\n",
    "hits = []\n",
    "\n",
    "file_path = \"../../resources/enterobacterales/test_blastp_blastn/results/hmmsearch/ss_hmmsearch_domtblout.txt\"\n",
    "\n",
    "results = SearchIO.parse(file_path, 'hmmscan3-domtab')\n",
    "\n",
    "for result in results:\n",
    "#    print(result.id)\n",
    "    for hit in result:\n",
    "#        print(hit.id)\n",
    "        for hsp in hit:\n",
    "            # print(hsp)\n",
    "            print(hsp.hit_id)\n",
    "            print(hsp.evalue)\n",
    "            print(hsp.hit_start)\n",
    "            print(hsp.query_start)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../resources/test_genome/test_new_args_4/results/hmmsearch/hmm_hits.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m df \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39;49mread_csv(\u001b[39m'\u001b[39;49m\u001b[39m../../resources/test_genome/test_new_args_4/results/hmmsearch/hmm_hits.csv\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:211\u001b[0m, in \u001b[0;36mdeprecate_kwarg.<locals>._deprecate_kwarg.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    210\u001b[0m         kwargs[new_arg_name] \u001b[39m=\u001b[39m new_arg_value\n\u001b[0;32m--> 211\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:331\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    325\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m>\u001b[39m num_allow_args:\n\u001b[1;32m    326\u001b[0m     warnings\u001b[39m.\u001b[39mwarn(\n\u001b[1;32m    327\u001b[0m         msg\u001b[39m.\u001b[39mformat(arguments\u001b[39m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[1;32m    328\u001b[0m         \u001b[39mFutureWarning\u001b[39;00m,\n\u001b[1;32m    329\u001b[0m         stacklevel\u001b[39m=\u001b[39mfind_stack_level(),\n\u001b[1;32m    330\u001b[0m     )\n\u001b[0;32m--> 331\u001b[0m \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:950\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    935\u001b[0m kwds_defaults \u001b[39m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    936\u001b[0m     dialect,\n\u001b[1;32m    937\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    946\u001b[0m     defaults\u001b[39m=\u001b[39m{\u001b[39m\"\u001b[39m\u001b[39mdelimiter\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39m,\u001b[39m\u001b[39m\"\u001b[39m},\n\u001b[1;32m    947\u001b[0m )\n\u001b[1;32m    948\u001b[0m kwds\u001b[39m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 950\u001b[0m \u001b[39mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:605\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    602\u001b[0m _validate_names(kwds\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnames\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mNone\u001b[39;00m))\n\u001b[1;32m    604\u001b[0m \u001b[39m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 605\u001b[0m parser \u001b[39m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    607\u001b[0m \u001b[39mif\u001b[39;00m chunksize \u001b[39mor\u001b[39;00m iterator:\n\u001b[1;32m    608\u001b[0m     \u001b[39mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1442\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1439\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptions[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m kwds[\u001b[39m\"\u001b[39m\u001b[39mhas_index_names\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[1;32m   1441\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles: IOHandles \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_engine \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_engine(f, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mengine)\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1735\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1733\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1734\u001b[0m         mode \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m-> 1735\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39m=\u001b[39m get_handle(\n\u001b[1;32m   1736\u001b[0m     f,\n\u001b[1;32m   1737\u001b[0m     mode,\n\u001b[1;32m   1738\u001b[0m     encoding\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1739\u001b[0m     compression\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mcompression\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1740\u001b[0m     memory_map\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mmemory_map\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mFalse\u001b[39;49;00m),\n\u001b[1;32m   1741\u001b[0m     is_text\u001b[39m=\u001b[39;49mis_text,\n\u001b[1;32m   1742\u001b[0m     errors\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mencoding_errors\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m\"\u001b[39;49m\u001b[39mstrict\u001b[39;49m\u001b[39m\"\u001b[39;49m),\n\u001b[1;32m   1743\u001b[0m     storage_options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49moptions\u001b[39m.\u001b[39;49mget(\u001b[39m\"\u001b[39;49m\u001b[39mstorage_options\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39mNone\u001b[39;49;00m),\n\u001b[1;32m   1744\u001b[0m )\n\u001b[1;32m   1745\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m   1746\u001b[0m f \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mhandles\u001b[39m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/pandas/io/common.py:856\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    851\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(handle, \u001b[39mstr\u001b[39m):\n\u001b[1;32m    852\u001b[0m     \u001b[39m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    853\u001b[0m     \u001b[39m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    854\u001b[0m     \u001b[39mif\u001b[39;00m ioargs\u001b[39m.\u001b[39mencoding \u001b[39mand\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mb\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m ioargs\u001b[39m.\u001b[39mmode:\n\u001b[1;32m    855\u001b[0m         \u001b[39m# Encoding\u001b[39;00m\n\u001b[0;32m--> 856\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(\n\u001b[1;32m    857\u001b[0m             handle,\n\u001b[1;32m    858\u001b[0m             ioargs\u001b[39m.\u001b[39;49mmode,\n\u001b[1;32m    859\u001b[0m             encoding\u001b[39m=\u001b[39;49mioargs\u001b[39m.\u001b[39;49mencoding,\n\u001b[1;32m    860\u001b[0m             errors\u001b[39m=\u001b[39;49merrors,\n\u001b[1;32m    861\u001b[0m             newline\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[1;32m    862\u001b[0m         )\n\u001b[1;32m    863\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    864\u001b[0m         \u001b[39m# Binary mode\u001b[39;00m\n\u001b[1;32m    865\u001b[0m         handle \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39m(handle, ioargs\u001b[39m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../resources/test_genome/test_new_args_4/results/hmmsearch/hmm_hits.csv'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../../resources/test_genome/test_new_args_4/results/hmmsearch/hmm_hits.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from Bio import SeqIO\n",
    "from Bio.Seq import Seq\n",
    "from Bio.SeqRecord import SeqRecord\n",
    "\n",
    "\n",
    "def pandas_df_to_fasta(dataframe, sequence_column, header_column, output_file):\n",
    "    records = []\n",
    "\n",
    "    for _, row in dataframe.iterrows():\n",
    "        seq_id = row[header_column]\n",
    "        sequence = row[sequence_column]\n",
    "        sequence = Seq(sequence)\n",
    "        record = SeqRecord(sequence, id=seq_id, description=\"\")\n",
    "        records.append(record)\n",
    "\n",
    "    with open(output_file, \"w\") as output_handle:\n",
    "        SeqIO.write(records, output_handle, \"fasta\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pephash</th>\n",
       "      <th>seq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>v1_PLS_30a7a42d3b5f6395cd721cca1240930eccfdd03...</td>\n",
       "      <td>MRELNSEEIRNVAGAGTDNPYDNPILLMNQIAENAAWGAALGAYGG...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>v1_PLS_b7c39251a51415725e47af1f392d4c7495fbdad...</td>\n",
       "      <td>MRLLNAAELKTVSGADPGYSDLL</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>v1_PLS_b3dfdade24c080bc500e5d3e6a5e157c0cb60b8...</td>\n",
       "      <td>MSLVDYAAARQSVPSRRYRFAPGLWLATFVMLLAVLAALFPAIFTQ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             pephash  \\\n",
       "0  v1_PLS_30a7a42d3b5f6395cd721cca1240930eccfdd03...   \n",
       "1  v1_PLS_b7c39251a51415725e47af1f392d4c7495fbdad...   \n",
       "2  v1_PLS_b3dfdade24c080bc500e5d3e6a5e157c0cb60b8...   \n",
       "\n",
       "                                                 seq  \n",
       "0  MRELNSEEIRNVAGAGTDNPYDNPILLMNQIAENAAWGAALGAYGG...  \n",
       "1                            MRLLNAAELKTVSGADPGYSDLL  \n",
       "2  MSLVDYAAARQSVPSRRYRFAPGLWLATFVMLLAVLAALFPAIFTQ...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../../resources/test_genome/test_new_args3/results/hmmsearch/hmm_hits.csv')\n",
    "df = df[[\"pephash\", \"seq\"]]\n",
    "#Trim * from seq\n",
    "df[\"seq\"] = df[\"seq\"].str.replace(\"*\", \"\", regex=False)\n",
    "df\n",
    "\n",
    "pandas_df_to_fasta(df, 'seq', 'pephash', 'test_out.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\"hmmsearch -E 10 --cpu 89 --tblout {output.tblout} --domtblout {output.domtblout} {input.hmmfile} {input.seqdb} > {output.fa}\"'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_queries = 0\n",
    "evalue = 10\n",
    "biased_composition_filter = True\n",
    "\n",
    "threads = int(90)\n",
    "if threads > 2:\n",
    "    cpu = threads - 1\n",
    "else: \n",
    "    cpu = 1\n",
    "\n",
    "# Generate string for running hmmsearch\n",
    "#setup = f'\"cpu=$(({threads} > 2 ? ({threads} - 1) : 1)) ; '\n",
    "command = f'\"hmmsearch -E {evalue} ' \n",
    "if num_queries == 0:\n",
    "    Z = ''\n",
    "else:\n",
    "    Z = f'-Z {num_queries} '\n",
    "if biased_composition_filter:\n",
    "    bias = ''\n",
    "else:\n",
    "    bias = '--nobias '\n",
    "T = f'--cpu {cpu} '\n",
    "end = '--tblout {output.tblout} --domtblout {output.domtblout} {input.hmmfile} {input.seqdb} > {output.fa}\"'\n",
    "\n",
    "hmmsearch = command + Z + bias + T + end\n",
    "hmmsearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of samples is 2\n",
      "i is 0\n",
      "count is -1\n",
      "sample is GCA_002554555.1_PDEG01.1\n",
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "i is 1\n",
      "count is 4\n",
      "sample is GCA_002554555.1_PDEG01.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "                     genome          contig\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000001.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000002.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000003.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000004.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000005.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000001.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000002.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000003.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000004.1\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000005.1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n",
      "/tmp/ipykernel_68158/1245304807.py:29: FutureWarning: The frame.append method is deprecated and will be removed from pandas in a future version. Use pandas.concat instead.\n",
      "  contig_to_genome_table = contig_to_genome_table.append(line)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#new shit\n",
    "SAMPLES = ['GCA_002554555.1_PDEG01.1', 'GCA_002554555.1_PDEG01.1']\n",
    "print('length of samples is ' + str(len(SAMPLES)))\n",
    "# Create empty DataFrame\n",
    "contig_to_genome_table = pd.DataFrame()\n",
    "subset_contig_to_genome = pd.DataFrame(columns=['genome', 'contig'])\n",
    "# Iterate through each sample\n",
    "count = -1\n",
    "for i in range(len(SAMPLES)):\n",
    "    print(\"i is \" + str(i))\n",
    "    print('count is ' + str(count))\n",
    "    # Assign sample to the current sample\n",
    "    sample = SAMPLES[i]\n",
    "\n",
    "    print(\"sample is \" + sample)\n",
    "    # Read ORF file and assign it to orfs_df\n",
    "    orfs_df = pd.read_csv(\"../../resources/test_genome/Test_read_files_may30/results/ORFs/\" + sample + \"_ORFs.csv\")\n",
    "#    print(orfs_df['sample'])\n",
    "    # Create a new column called 'sample' and assign it to the sample name\n",
    "    for j in range(len(orfs_df['sample'].unique())):\n",
    "        count += 1\n",
    "        print(count)\n",
    "        #make dataframe with two columns, \n",
    "        line = pd.DataFrame([[sample, orfs_df['sample'].unique()[j]]], columns=['genome', 'contig'])\n",
    "\n",
    "        # Append orfs_df to contig_to_genome_table\n",
    "        contig_to_genome_table = contig_to_genome_table.append(line)\n",
    "\n",
    "\n",
    "print(contig_to_genome_table)\n",
    "\n",
    "# # Write the final completed DataFrame to the output file\n",
    "# print(contig_to_genome_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of samples is 2\n",
      "                     genome          contig\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000001.1\n",
      "1  GCA_002554555.1_PDEG01.1  PDEG01000002.1\n",
      "2  GCA_002554555.1_PDEG01.1  PDEG01000003.1\n",
      "3  GCA_002554555.1_PDEG01.1  PDEG01000004.1\n",
      "4  GCA_002554555.1_PDEG01.1  PDEG01000005.1\n",
      "5  GCA_002554555.1_PDEG01.1  PDEG01000001.1\n",
      "6  GCA_002554555.1_PDEG01.1  PDEG01000002.1\n",
      "7  GCA_002554555.1_PDEG01.1  PDEG01000003.1\n",
      "8  GCA_002554555.1_PDEG01.1  PDEG01000004.1\n",
      "9  GCA_002554555.1_PDEG01.1  PDEG01000005.1\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# New code\n",
    "SAMPLES = ['GCA_002554555.1_PDEG01.1', 'GCA_002554555.1_PDEG01.1']\n",
    "print('Length of samples is ' + str(len(SAMPLES)))\n",
    "\n",
    "# Create empty DataFrame\n",
    "contig_to_genome_table = pd.DataFrame()\n",
    "subset_contig_to_genome = pd.DataFrame(columns=['genome', 'contig'])\n",
    "\n",
    "# Iterate through each sample\n",
    "count = -1\n",
    "for i in range(len(SAMPLES)):    \n",
    "    # Assign sample to the current sample\n",
    "    sample = SAMPLES[i]\n",
    "    \n",
    "    # Read ORF file and assign it to orfs_df\n",
    "    orfs_df = pd.read_csv(\"../../resources/test_genome/Test_read_files_may30/results/ORFs/\" + sample + \"_ORFs.csv\")\n",
    "\n",
    "    # Create a new column called 'sample' and assign it to the sample name\n",
    "    for j in range(len(orfs_df['sample'].unique())):\n",
    "        count += 1\n",
    "        \n",
    "        # Make DataFrame with two columns\n",
    "        line = pd.DataFrame([[sample, orfs_df['sample'].unique()[j]]], columns=['genome', 'contig'])\n",
    "        \n",
    "        # Concatenate line with contig_to_genome_table\n",
    "        contig_to_genome_table = pd.concat([contig_to_genome_table, line], ignore_index=True)\n",
    "    \n",
    "\n",
    "# Write the final completed DataFrame to the output file\n",
    "print(contig_to_genome_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDEG01000002.1\n",
      "0    False\n",
      "1     True\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: contig, dtype: bool\n",
      "                     genome          contig\n",
      "1  GCA_002554555.1_PDEG01.1  PDEG01000002.1\n",
      "PDEG01000001.1\n",
      "0     True\n",
      "1    False\n",
      "2    False\n",
      "3    False\n",
      "4    False\n",
      "Name: contig, dtype: bool\n",
      "                     genome          contig\n",
      "0  GCA_002554555.1_PDEG01.1  PDEG01000001.1\n"
     ]
    }
   ],
   "source": [
    "# Load hits\n",
    "extracted_df = pd.read_csv('../../resources/test_genome/Test_read_files_may30/results/hmmsearch/extracted_hits.csv').rename(columns={'id': 'contig'})\n",
    "\n",
    "# Add blank columns\n",
    "added_columns = ['id', 'pephash', 'sample', 'start', 'stop', 'strand', 'dna', 'seq']\n",
    "for column in added_columns:\n",
    "    extracted_df[column] = ''\n",
    "\n",
    "contig_to_genome_table = pd.read_csv('../../resources/test_genome/Test_read_files_may30/results/ORFs/contig_to_genome_table.csv')\n",
    "\n",
    "# Iterate through each row of extracted_df\n",
    "for i in range(len(extracted_df)):\n",
    "    # Find the genome that the contig belongs to\n",
    "    print(extracted_df.loc[i, 'contig'].split('_')[0])\n",
    "    print(contig_to_genome_table['contig'] == extracted_df.loc[i, 'contig'].split('_')[0])\n",
    "    print(contig_to_genome_table[contig_to_genome_table['contig'] == extracted_df.loc[i, 'contig'].split('_')[0]])\n",
    "#     print(genome_row)\n",
    "# #    genome_row = contig_to_genome_table[contig_to_genome_table['contig'] == extracted_df.loc[i, 'contig']]\n",
    "#     if not genome_row.empty:\n",
    "#         genome = genome_row.iloc[0]['genome']\n",
    "\n",
    "#         # Generate the string for ORF file for the genome found\n",
    "#         orf_file = \"../../resources/test_genome/Test_read_files_may30/results/ORFs/\" + genome + \"_ORFs.csv\"\n",
    "\n",
    "#         # Read ORF file and assign it to orfs_df\n",
    "#         orfs_df = pd.read_csv(orf_file)\n",
    "#         # Find the row in orfs_df that matches the 'contig' (should be only 1)\n",
    "#         matching_row = orfs_df[orfs_df['contig'] == extracted_df.loc[i, 'contig']]\n",
    "#         # Add values from columns to extracted_df\n",
    "#         for column in added_columns:\n",
    "#             extracted_df.loc[i, column] = matching_row.loc[0,column]\n",
    "\n",
    "# # Write the final completed DataFrame to the output file\n",
    "# print(extracted_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
